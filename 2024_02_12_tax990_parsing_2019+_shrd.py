# -*- coding: utf-8 -*-
"""2024-02-12-Tax990-Parsing-2019+-Shrd.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_aMgWvQ_GJie5rfN4hcrvkYgzGVw7_YR

## Install
"""

!pip install pymupdf

import os
import pandas as pd
import fitz  # PyMuPDF
import re
import logging

"""## 990 2018 +"""

def setup_logging():
    """
    Setup logging configuration.
    """
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def extract_text_from_pdf(pdf_path):
    """
    Extract text from a PDF file.
    """
    text = ""
    try:
        pdf_document = fitz.open(pdf_path)
        for page_number in range(len(pdf_document)):
            page = pdf_document.load_page(page_number)
            text += page.get_text()
        pdf_document.close()
    except Exception as e:
        logging.error(f"Error occurred while extracting text from {pdf_path}: {e}")
    return text

def remove_special_characters(input_string):
    return input_string.replace('\xa0', ' ')

def extract_info(pdf_text, patterns):
    """
    Extract information from PDF text based on provided patterns.
    """
    info_dict = {}
    for key, pattern in patterns.items():
        match = re.search(pattern, pdf_text, re.DOTALL)
        if match:
            info_dict[key] = match.group(1).strip()
    return info_dict

def process_pdf(pdf_path, patterns):
    """
    Process a single PDF file.
    """
    # Extract text from PDF
    text_content = extract_text_from_pdf(pdf_path)

    # Remove spaces and special characters
    pdf_text = remove_special_characters(text_content)

    # Extract information from PDF text
    info_dict = extract_info(pdf_text, patterns)

    # Initialize DataFrame
    df = pd.DataFrame(info_dict, index=[0])

    return df

def main(pdf_directory, patterns):
    """
    Main function to extract information from multiple PDFs and concatenate results.
    """
    # List PDF files in the directory
    pdf_files = [file for file in os.listdir(pdf_directory) if file.endswith('.pdf')]

    # Process each PDF file
    dfs = []
    for pdf_file in pdf_files:
        pdf_path = os.path.join(pdf_directory, pdf_file)
        df = process_pdf(pdf_path, patterns)
        dfs.append(df)

    # Concatenate DataFrames
    final_df = pd.concat(dfs, ignore_index=True)
    # Replace '\n' with ' ' in all columns
    final_df = final_df.apply(lambda x: x.str.replace('\n', ' '))

    return final_df

if __name__ == "__main__":
    setup_logging()
    pdf_directory = '/content/drive/MyDrive/G14-USFSR1/data990form/test_2019after'  # Directory containing PDF files
    patterns = {
        "EIN": r"Employer identification\nnumber\n(.*?)\nE Telephone number",
        "Organization": r"\nApplication pending\n(.*?)\nC Name of organization",
        "Year": r"For the(.*?)calendar year, or tax year beginning",
        "Street": r"\nC Name of organization\n(.*?)\nNumber and street",
        "CityStateZip": r"Room/suite\n(.*?)\n City or town, state or province,",
        "Revenue": r"\nTotal revenue. Add lines 1, 2, 3, 4, 5c, 6d, 7c, and 8\n9\n(.*?)\n10"
    }
    try:
        df = main(pdf_directory, patterns)

    except Exception as e:
        logging.error(f"An error occurred: {e}")